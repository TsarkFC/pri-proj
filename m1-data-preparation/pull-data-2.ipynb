{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all available news from publico.pt.\n",
    "To choose only tech news change urlPublico to the following\n",
    "'''python\n",
    "def urlPublico(year, month, day):\n",
    "    return \"https://arquivo.pt/wayback/cdx?url=publico.pt/{year:04d}/{month:02d}/{day:02d}/tecnologia&matchType=prefix&output=json\".format(year = year, month = month, day = day)\n",
    "'''\n",
    "To get news from different dates change start_date and/or end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, datetime, time, json\n",
    "\n",
    "def urlPublico(year, month, day):\n",
    "    return \"https://arquivo.pt/wayback/cdx?url=publico.pt/{year:04d}/{month:02d}/{day:02d}/&matchType=prefix&output=json\".format(year = year, month = month, day = day)\n",
    "\n",
    "output = []\n",
    "\n",
    "start_date = datetime.date(2021, 1, 1)\n",
    "end_date = datetime.date(2021, 1, 5)\n",
    "date = start_date\n",
    "\n",
    "while (date < end_date):\n",
    "    if (date.day == 1):\n",
    "        print(date)\n",
    "    r = requests.get(url = urlPublico(date.year, date.month, date.day))\n",
    "    if (r.status_code == 200 and r.text != \"\"):\n",
    "        for line in r.text.split('\\n'):\n",
    "            if (line != \"\"):\n",
    "                output.append(json.loads(line))\n",
    "    elif (r.status_code == 429):\n",
    "        print(\"Reached threshold. Waiting 10 seconds\")\n",
    "        time.sleep(10)\n",
    "    date = date + datetime.timedelta(days = 1)\n",
    "\n",
    "results = {\"publico\" : output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of news on a site\n",
    "for identifier, result in results.items():\n",
    "    print(\"site: {0}\\t noticias: {1}\".format(identifier, len(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear the news that were fetched.\n",
    "Multiple news with different timestamps are cleared.\n",
    "Some websites that are not news are cleared.\n",
    "Count the number of indexations for each of the news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear repeated news\n",
    "news = {}\n",
    "number_of_indexations = {}\n",
    "\n",
    "for identifier, result in results.items():\n",
    "    for link in result:\n",
    "        splitted_url = link['url'].split('/')\n",
    "        if (len(splitted_url) < 9): # not news\n",
    "            continue\n",
    "        tittle = splitted_url[8]\n",
    "        if (\".\" in tittle): # not news\n",
    "            continue\n",
    "        if (news.get(tittle) == None):\n",
    "            news[tittle] = link\n",
    "            number_of_indexations[tittle] = 1\n",
    "        else:\n",
    "            number_of_indexations[tittle] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the website for the links obtained.\n",
    "Some sites need to be cleaned (they are not news)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = {}\n",
    "\n",
    "def create_website_link(url, timestamp):\n",
    "    return \"https://arquivo.pt/noFrame/replay/{0}/{1}\".format(timestamp, url)\n",
    "\n",
    "for tittle, link in news.items():\n",
    "    response = requests.get(create_website_link(link['url'], link['timestamp']))\n",
    "    websites[tittle] = response.text\n",
    "\n",
    "# len between 372500 and 37599 might be 404 page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end we have 3 dictionaries with the same keys (tittle of the news).\n",
    "News has all the info provided in the initial API requests.\n",
    "Number_of_indexations has the number of different timestamps for each website.\n",
    "Websites contains the HTML for each of the websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(websites))\n",
    "print(news['amigo-cunhal-compagnon-route-pcp-apoiante-costa-1944794'])\n",
    "print(number_of_indexations['amigo-cunhal-compagnon-route-pcp-apoiante-costa-1944794'])\n",
    "print(websites['amigo-cunhal-compagnon-route-pcp-apoiante-costa-1944794'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
